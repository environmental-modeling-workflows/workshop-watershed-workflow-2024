{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import shapely\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import watershed_workflow \n",
    "import watershed_workflow.source_list\n",
    "import watershed_workflow.crs\n",
    "import watershed_workflow.utils\n",
    "import watershed_workflow.plot\n",
    "import watershed_workflow.mesh\n",
    "import watershed_workflow.densification\n",
    "import watershed_workflow.condition\n",
    "\n",
    "import watershed_workflow.ui\n",
    "watershed_workflow.ui.setup_logging(1)\n",
    "\n",
    "crs = watershed_workflow.crs.daymet_crs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SplitHucs \n",
    "\n",
    "<b> Class for dealing with the multiple interacting views of HUCs </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just download some data... a collection of HUC 8 polygons in '0601'\n",
    "source = watershed_workflow.source_list.FileManagerNHDPlus()\n",
    "#_, hucs = watershed_workflow.get_hucs(source, '0601', 8, crs)\n",
    "with open('../../Coweeta_data/input_data/hydrography/hucs.pkl', 'rb') as fid:\n",
    "    hucs_with_properties = pickle.load(fid)\n",
    "    hucs = [shapely.geometry.Polygon(h[0]) for h in hucs_with_properties]\n",
    "    for huc, props in zip(hucs, hucs_with_properties):\n",
    "        huc.properties = props[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the HUCs we got:\n",
    "watershed_workflow.plot.shplys(hucs, crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key concept**\n",
    "\n",
    "These polygons share common boundaries that (nearly exactly) coincide.  Once we start to simplify them, or to snap them to river nodes, or to otherwise turn them into something suitable for a mesh, they will not necessarily coincide.  _We need polygons that share a common boundary to be **discretely** the same._\n",
    "\n",
    "The `SplitHUCs` object is used to ensure shared boundaries stay discretely the same through all transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_hucs = watershed_workflow.split_hucs.SplitHUCs(hucs)\n",
    "split_hucs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting object stores segments, which may be on the exterior or interior boundary, and collections of those segments that can be combined to re-form the original polygons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HUC Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many segments were formed?  What is a segment? (a shapely LineString)\n",
    "print(len(split_hucs.segments))\n",
    "split_hucs.segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all segments\n",
    "watershed_workflow.plot.shplys(split_hucs.segments, crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HUC Polygons\n",
    "\n",
    "Reforming the polygons is straightforward by calling the API, but realize that you shouldn't keep these polygons -- let the `SplitHUCs` object manage them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a specific polygon\n",
    "split_hucs.polygon(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over each polygon\n",
    "split_hucs.polygons() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. sum the area:\n",
    "area = sum(poly.area for poly in split_hucs.polygons())\n",
    "print('Total area =', area, 'm^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or get the interior\n",
    "split_hucs.exterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SplitHUCs saves properties\n",
    "dict(split_hucs.polygon(3).properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rivers\n",
    "\n",
    "Watershed Workflow assumes that all rivers are dendritic, and so stores **rivers** as a tree data structure, called `River`.\n",
    "\n",
    "### Reaches\n",
    "Throughout, we will use the word **reach** to define the shapely `LineString` representing a segment of a river.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coweeta Hydrologic Lab will be used as our test area\n",
    "_, coweeta = watershed_workflow.get_shapes('../../Coweeta_data/input_data/coweeta_basin.shp', out_crs=crs)\n",
    "coweeta = coweeta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some data -- all reaches in Coweeta\n",
    "#_, reaches = watershed_workflow.get_reaches(source, '0601', coweeta, \n",
    "#                                            in_crs=crs, out_crs=crs,\n",
    "#                                            in_network=True, properties=True)\n",
    "\n",
    "with open('../../Coweeta_data/input_data/hydrography/reaches.pkl', 'rb') as fid:\n",
    "    reaches_with_properties = pickle.load(fid)\n",
    "    reaches = []\n",
    "    for reach, props in reaches_with_properties:\n",
    "        line = shapely.geometry.LineString(reach)\n",
    "        line.properties = props\n",
    "        reaches.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the watershed and reaches\n",
    "fig, ax = watershed_workflow.plot.get_ax(crs, figsize=(3,3))\n",
    "watershed_workflow.plot.shply(coweeta, crs, 'k', ax)\n",
    "watershed_workflow.plot.shplys(reaches, crs, None, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these reaches come with properties, including NHDPlus Value Added Attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(reaches[0].properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rivers are constructed using collection of reaches using one of the two methods:\n",
    "\n",
    "1) `geometry` looks at coincident coordinates.  This is needed when working with non-NHD data.\n",
    "2) `hydroseq` valid only for NHDPlus data, this uses the  NHDPlus VAA tables Hydrologic Sequence. If using this method, get_reaches() must have been called with both\n",
    "  'HydrologicSequence' and 'DownstreamMainPathHydroSeq' properties requested (or properties=True).  This is the better method if working with NHD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers = watershed_workflow.construct_rivers(reaches, method='hydroseq')\n",
    "river = rivers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "watershed_workflow.plot.rivers(rivers, ax=ax, crs=None)\n",
    "ax.set_aspect('equal', adjustable='box')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### River node\n",
    "\n",
    "A `River` is a composed of nodes. A single node in the River is also a `River` object, representing one reach and its upstream children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "river = rivers[0]\n",
    "node = river\n",
    "\n",
    "# the node's reach segment\n",
    "node.segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the node's upstream (contributing) children reaches are themselves River objects\n",
    "node.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = watershed_workflow.plot.get_ax(crs, figsize=(3,3))\n",
    "watershed_workflow.plot.rivers(node.children, crs, ax=ax)\n",
    "watershed_workflow.plot.shply(node.segment, crs, 'k', ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversing Tree Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic tree traversal uses the `preOrder()` method, which is a depth-first traversal of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [node for node in river.preOrder()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access individial nodes and its \"relatives\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access individual nodes\n",
    "node = nodes[0]  ##### CHANGE TO 2, 3, .. and march up the river #####\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3,3))\n",
    "watershed_workflow.plot.river(node, ax=ax, crs=None, color='b')\n",
    "ax.set_aspect('equal', adjustable='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access siblings\n",
    "node = nodes[1]\n",
    "siblings = list(node.siblings()); print(siblings)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3,3))\n",
    "watershed_workflow.plot.river(node, crs, 'b', ax)\n",
    "watershed_workflow.plot.rivers(siblings, crs, 'r', ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access parent\n",
    "parent = node.parent\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "watershed_workflow.plot.river(node, crs, 'b', ax)\n",
    "watershed_workflow.plot.shply(parent.segment, crs, 'r', ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing the River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reach_backup = river.segment\n",
    "\n",
    "# move some coordinates\n",
    "for i in range(50,400):\n",
    "    river.moveCoordinate(i, np.array(river.segment.coords[i]) + np.array([0, 100]))\n",
    "\n",
    "# plot\n",
    "watershed_workflow.plot.shplys([river.segment, reach_backup], crs)\n",
    "\n",
    "# revert that change!\n",
    "river.segment = reach_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "river.is_continuous()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watershed_workflow-pure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
