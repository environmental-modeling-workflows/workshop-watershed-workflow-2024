{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Creating Stream Mesh Labeled Sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regions in the stream mesh can be very useful to provide river-specific properties, provide sources and sinks or set observations in the entire or part of stream network. One can go to the granulatity of individual reaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda package imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "import copy\n",
    "import shapely\n",
    "import pickle\n",
    "\n",
    "import watershed_workflow \n",
    "import watershed_workflow.source_list\n",
    "import watershed_workflow.ui\n",
    "import watershed_workflow.crs\n",
    "import watershed_workflow.densification\n",
    "import watershed_workflow.mesh\n",
    "import watershed_workflow.regions\n",
    "watershed_workflow.ui.setup_logging(1,None)\n",
    "\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters cell -- this provides all parameters that can be changed via pipelining to generate a new watershed. \n",
    "coweeta_shapefile = '../../Coweeta_data/input_data/coweeta_basin.shp'\n",
    "hint = '0601'  # hint: HUC 4 containing this shape.  \n",
    "               # This is necessary to avoid downloading all HUCs to search for this shape\n",
    "name = 'Coweeta'\n",
    "\n",
    "figsize = (6,6)\n",
    "figsize_3d = (8,6)\n",
    "\n",
    "# Geomtric parameters tuning the degree of cleaning of the raw data and scales of hydrologic features to be considered\n",
    "simplify = 60 # length scale to target average edge\n",
    "ignore_small_rivers = 2 \n",
    "prune_by_area_fraction = 0.01 \n",
    "\n",
    "# huc boundary refinement control\n",
    "refine_d0 = 20\n",
    "refine_d1 = 100\n",
    "refine_L0 = 70\n",
    "refine_L1 = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that, by default, we tend to work in the DayMet CRS because this allows us to avoid\n",
    "# reprojecting meteorological forcing datasets.\n",
    "crs = watershed_workflow.crs.daymet_crs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources and setup\n",
    "\n",
    "Next we set up the source watershed and coordinate system and all data sources for our mesh.  We will use the CRS that is included in the shapefile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A wide range of data sources are available; here we use the defaults except for using NHD Plus for watershed boundaries and hydrography (the default is NHD, which is lower resolution and therefore smaller download sizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dictionary of source objects\n",
    "sources = watershed_workflow.source_list.get_default_sources()\n",
    "sources['hydrography'] = watershed_workflow.source_list.hydrography_sources['NHD Plus']\n",
    "sources['HUC'] = watershed_workflow.source_list.huc_sources['NHD Plus']\n",
    "sources['DEM'] = '../../Coweeta_data/input_data/DEM/coweeta_dem.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get HUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hucs from shape\n",
    "_, watershed = watershed_workflow.get_split_form_shapes(coweeta_shapefile, out_crs=crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Rivers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geomtric parameters tuning the degree of cleaning of the raw data and scales of hydrologic features to be considered\n",
    "ignore_small_rivers = 2 \n",
    "prune_by_area_fraction = 0.01 \n",
    "\n",
    "# download/collect the river network within that shape's bounds\n",
    "# _, reaches = watershed_workflow.get_reaches(sources['hydrography'], hint, \n",
    "#                                             watershed.exterior(), crs, crs,\n",
    "#                                             in_network=True, properties=True)\n",
    "\n",
    "with open('../../Coweeta_data/input_data/hydrography/reaches.pkl', 'rb') as fid:\n",
    "    reaches_with_properties = pickle.load(fid)\n",
    "    reaches = []\n",
    "    for reach, props in reaches_with_properties:\n",
    "        line = shapely.geometry.LineString(reach)\n",
    "        line.properties = props\n",
    "        reaches.append(line)        \n",
    "\n",
    "rivers = watershed_workflow.construct_rivers(reaches, method='hydroseq',\n",
    "                                                ignore_small_rivers=ignore_small_rivers,\n",
    "                                                prune_by_area=prune_by_area_fraction * watershed.exterior().area * 1.e-6,\n",
    "                                                remove_diversions=True,\n",
    "                                                remove_braided_divergences=True)\n",
    "\n",
    "# keeping the originals\n",
    "rivers_orig=[river.deepcopy() for river in rivers]\n",
    "watershed_orig=copy.deepcopy(watershed) \n",
    "\n",
    "# simplifying \n",
    "rivers = watershed_workflow.simplify(watershed, rivers, simplify_hucs=simplify, simplify_rivers=simplify,\n",
    "                            snap_tol=0.75*simplify, cut_intersections=True)\n",
    "\n",
    "# for plotting purpose only\n",
    "rivers_simplified=[river.deepcopy() for river in rivers] \n",
    "watershed_simplified=copy.deepcopy(watershed) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densification of River Network and Watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = refine_d0; d1 = refine_d1\n",
    "L0 = refine_L0; L1 = refine_L1 \n",
    "\n",
    "# densify_watershed\n",
    "watershed_workflow.densification.densify_hucs(watershed, watershed_orig, rivers, limit_scales=[d0,L0,d1,L1]) \n",
    "\n",
    "#densify_river\n",
    "watershed_workflow.densification.densify_rivers_new(rivers, limit=70)\n",
    "\n",
    "\n",
    "# treat sharp angles\n",
    "watershed_workflow.densification.remove_sharp_angles(rivers, watershed, angle_limit=10, junction_angle_limit=10, huc_seg_river_angle_limit=10, limit=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot re-densified watershed and river network\n",
    "fig, ax = plt.subplots(subplot_kw={'projection':watershed_workflow.crs.to_cartopy(crs)}, figsize=(6,4))\n",
    "\n",
    "ax.plot(watershed.exterior().exterior.xy[0], watershed.exterior().exterior.xy[1], 'k-x')\n",
    "ax.set_title('re-densified',fontsize=16)\n",
    "\n",
    "for river in rivers:\n",
    "    for node in river.preOrder():\n",
    "        x,y=node.segment.xy \n",
    "        ax.plot(x,y,'-o',markersize=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many types of Stream Orders are there\n",
    "set([r.properties[\"StreamOrder\"] for r in rivers[0].preOrder()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meshing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Triangulation\n",
    "\n",
    "# Refine triangles if they get too acute\n",
    "min_angle = 32 # degrees\n",
    "\n",
    "# width of reach by stream order (order:width)\n",
    "widths = dict({1:8,2:12,3:16})\n",
    "\n",
    "mesh_points2, conn_list, areas, dists = watershed_workflow.tessalate_river_aligned(watershed,rivers, river_width=widths,\n",
    "                                              refine_min_angle=min_angle, refine_max_area=30000,\n",
    "                                              diagnostics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a raster for the elevation map, based on NED\n",
    "dem_profile, dem = watershed_workflow.get_raster_on_shape(sources['DEM'], watershed.exterior(), crs)\n",
    "\n",
    "# elevate the triangle nodes to the dem\n",
    "mesh_points3 = watershed_workflow.elevate(mesh_points2, crs, dem, dem_profile)\n",
    "\n",
    "# construct the 2D mesh\n",
    "m2 = watershed_workflow.mesh.Mesh2D(mesh_points3.copy(), conn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting surface mesh with elevations\n",
    "start=min(m2.centroids[:,2])\n",
    "step=(max(m2.centroids[:,2])-(min(m2.centroids[:,2])))/40\n",
    "stop=max(m2.centroids[:,2])+step\n",
    "legend_values=np.arange(start,stop,step)\n",
    "indices, cmap, norm, ticks, labels = watershed_workflow.colors.generate_indexed_colormap(legend_values, cmap='terrain')\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = watershed_workflow.plot.get_ax(crs, fig, window=[0.05,0.1,0.9,0.8])\n",
    "cbax = fig.add_axes([0.05,0.05,0.9,0.05])\n",
    "\n",
    "mp = watershed_workflow.plot.mesh(m2, crs, ax=ax, \n",
    "                        linewidth=0.5 ,color=m2.centroids[:,2], \n",
    "                        cmap=cmap, norm = norm, edgecolor='k', facecolor='color')\n",
    "cbar = fig.colorbar(mp, orientation=\"horizontal\", cax=cbax)\n",
    "ax.set_title('surface mesh with elevations')\n",
    "ax.set_aspect('equal', 'datalim')\n",
    "\n",
    "cbar.ax.set_title('elevation [m]')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Mesh Labeled Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Sets for Stream Corridor\n",
    "\n",
    "A single labeled set is created stream/river mesh elements for reach stream/river network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_workflow.regions.add_river_corridor_regions(m2, rivers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Sets for Reaches as per Stream Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_workflow.regions.add_regions_by_stream_order_rivers(m2, rivers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Sets Individual Reaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reach_ids = ['25000400108019', '25000400040729']\n",
    "reach_labels = ['reach1', 'reach2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for river in rivers:\n",
    "    watershed_workflow.regions.add_region_by_reach_id(m2, river, reach_ids=reach_ids, labels=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see labeled sets we have created for stream mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ls in m2.labeled_sets:\n",
    "    print(f'{ls.setid} : {ls.entity} : {len(ls.ent_ids)} : \"{ls.name}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watershed_workflow-pure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
