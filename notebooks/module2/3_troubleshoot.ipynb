{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Simplify and Redensify a Watershed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda package imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "import copy\n",
    "import shapely\n",
    "\n",
    "import watershed_workflow \n",
    "import watershed_workflow.source_list\n",
    "import watershed_workflow.ui\n",
    "import watershed_workflow.crs\n",
    "import watershed_workflow.densification\n",
    "watershed_workflow.ui.setup_logging(1,None)\n",
    "\n",
    "import ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters cell -- this provides all parameters that can be changed via pipelining to generate a new watershed. \n",
    "coweeta_shapefile = '../../Coweeta_data/input_data/coweeta_basin.shp'\n",
    "hint = '0601'  # hint: HUC 4 containing this shape.  \n",
    "               # This is necessary to avoid downloading all HUCs to search for this shape\n",
    "name = 'Coweeta'\n",
    "\n",
    "figsize = (6,6)\n",
    "figsize_3d = (8,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that, by default, we tend to work in the DayMet CRS because this allows us to avoid\n",
    "# reprojecting meteorological forcing datasets.\n",
    "crs = watershed_workflow.crs.daymet_crs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString\n",
    "def trim_linestring(linestring, fraction, from_up=True):\n",
    "    total_length = linestring.length\n",
    "    trim_length = total_length * fraction\n",
    "\n",
    "    if from_up:\n",
    "        # Trimming from the start\n",
    "        current_length = 0\n",
    "        for i, point in enumerate(linestring.coords[:-1]):\n",
    "            segment = LineString([point, linestring.coords[i + 1]])\n",
    "            current_length += segment.length\n",
    "            if current_length >= trim_length:\n",
    "                return LineString([segment.interpolate(current_length - trim_length)] + linestring.coords[i + 1:])\n",
    "\n",
    "    else:\n",
    "        # Trimming from the end (original method)\n",
    "        trimmed_length = total_length - trim_length\n",
    "        current_length = 0\n",
    "        for i, point in enumerate(linestring.coords[:-1]):\n",
    "            segment = LineString([point, linestring.coords[i + 1]])\n",
    "            current_length += segment.length\n",
    "            if current_length >= trimmed_length:\n",
    "                return LineString(linestring.coords[:i + 1] + [segment.interpolate(trimmed_length - (current_length - segment.length))])\n",
    "\n",
    "    return linestring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dictionary of source objects\n",
    "sources = watershed_workflow.source_list.get_default_sources()\n",
    "sources['hydrography'] = watershed_workflow.source_list.hydrography_sources['NHD Plus']\n",
    "sources['HUC'] = watershed_workflow.source_list.huc_sources['NHD Plus']\n",
    "\n",
    "watershed_workflow.source_list.log_sources(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get HUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hucs from shape\n",
    "_, watershed = watershed_workflow.get_split_form_shapes(coweeta_shapefile, out_crs=crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Rivers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/coweeta_rivers_pickle\", 'rb') as handle:\n",
    "    rivers = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick look at rivers and watershed boundary\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = watershed_workflow.plot.get_ax(crs, fig, window=[0.05,0.1,0.9,0.8])\n",
    "watershed_workflow.plot.hucs(watershed, crs, 'k', ax)\n",
    "watershed_workflow.plot.rivers(rivers, crs, 'b', ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplify = 60 # length scale to target average edge, ; set this as 1 or 2 when using new densify \n",
    "snap_tol = 40\n",
    "# keeping the originals\n",
    "rivers_orig=[river.deepcopy() for river in rivers]\n",
    "watershed_orig=copy.deepcopy(watershed) \n",
    "\n",
    "# simplifying \n",
    "rivers = watershed_workflow.simplify(watershed, rivers, simplify_hucs=simplify, simplify_rivers=simplify,\n",
    "                            snap_tol=snap_tol, cut_intersections=True)\n",
    "\n",
    "# for plotting purpose only\n",
    "rivers_simplified=[river.deepcopy() for river in rivers] \n",
    "watershed_simplified=copy.deepcopy(watershed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error is because a reach has two intersections with the watershed boundary, a case of inconsistent data of mapped flowlines for river and watershed boundary. As a remedy, we could either trim the reach or move the river or watershed boundary segment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Trim the reach\n",
    "\n",
    "We can get the problematic node using either node ID (if the dataset is from NHDPlus, this is NHD_ID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert to original river\n",
    "rivers = [river.deepcopy() for river in rivers_orig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the problematic node\n",
    "node_id = '25000400108019'\n",
    "node = rivers[0].getNode(node_id)\n",
    "node.segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting original and simplified-pruned rivers and watershed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_reach_segment = trim_linestring(node.segment, 0.25, from_up=True) # Trims from upstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a loot at trimmed node\n",
    "# quick look at rivers and watershed boundary\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = watershed_workflow.plot.get_ax(crs, fig, window=[0.05,0.1,0.9,0.8])\n",
    "watershed_workflow.plot.hucs(watershed, crs, 'k', ax)\n",
    "watershed_workflow.plot.rivers(rivers, crs, 'b', ax)\n",
    "watershed_workflow.plot.shply(trimmed_reach_segment, crs, 'r', ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the edited reach segment back to the node\n",
    "node.segment = trimmed_reach_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick look at rivers and watershed boundary after editing river\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = watershed_workflow.plot.get_ax(crs, fig, window=[0.05,0.1,0.9,0.8])\n",
    "watershed_workflow.plot.hucs(watershed, crs, 'k', ax)\n",
    "watershed_workflow.plot.rivers(rivers, crs, 'b', ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplifying \n",
    "rivers = watershed_workflow.simplify(watershed, rivers, simplify_hucs=simplify, simplify_rivers=simplify,\n",
    "                            snap_tol=0.75*simplify, cut_intersections=True)\n",
    "\n",
    "# for plotting purpose only\n",
    "rivers_simplified=[river.deepcopy() for river in rivers] \n",
    "watershed_simplified=copy.deepcopy(watershed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers[0].is_continuous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Remove the reach\n",
    "\n",
    "We can get the problematic node using either node ID (if the dataset is from NHDPlus, this is NHD_ID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert to original river\n",
    "rivers = [river.deepcopy() for river in rivers_orig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the problematic node\n",
    "node_id = '25000400108019'\n",
    "node = rivers[0].getNode(node_id)\n",
    "node.segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the problematic node\n",
    "node.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick look at rivers to see if the problematic node is removed\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = watershed_workflow.plot.get_ax(crs, fig, window=[0.05,0.1,0.9,0.8])\n",
    "watershed_workflow.plot.hucs(watershed, crs, 'k', ax)\n",
    "watershed_workflow.plot.rivers(rivers, crs, 'b', ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers[0].is_continuous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Nudge the reach\n",
    "\n",
    "We can get the problematic node using either node ID (if the dataset is from NHDPlus, this is NHD_ID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert to original river\n",
    "rivers = [river.deepcopy() for river in rivers_orig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the problematic node\n",
    "node_id = '25000400108019'\n",
    "node = rivers[0].getNode(node_id)\n",
    "node.segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reach_backup = node.segment\n",
    "\n",
    "# move some coordinates\n",
    "for i in range(0,50):\n",
    "    node.moveCoordinate(i, np.array(node.segment.coords[i]) + np.array([-320*(49-i)/50,0]))\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = watershed_workflow.plot.get_ax(crs, fig, window=[0.05,0.1,0.9,0.8])\n",
    "watershed_workflow.plot.hucs(watershed, crs, 'k', ax)\n",
    "watershed_workflow.plot.rivers(rivers, crs, 'b', ax)\n",
    "watershed_workflow.plot.shply(reach_backup, crs, 'r', ax, marker='x', markersize=2)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # revert that change!\n",
    "# river.segment = reach_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplifying \n",
    "rivers = watershed_workflow.simplify(watershed, rivers, simplify_hucs=simplify, simplify_rivers=simplify,\n",
    "                            snap_tol=0.75*simplify, cut_intersections=True)\n",
    "\n",
    "# for plotting purpose only\n",
    "rivers_simplified=[river.deepcopy() for river in rivers] \n",
    "watershed_simplified=copy.deepcopy(watershed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers[0].is_continuous()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watershed_workflow-pure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
